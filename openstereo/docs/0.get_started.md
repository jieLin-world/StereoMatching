# Get Started

## Installation

1. clone this repo.
    ```
    https://github.com/XiandaGuo/OpenStereo
    ```
2. Install dependenices:
    - pytorch >= 1.13.1
    - torchvision
    - timm == 0.5.4
    - pyyaml
    - tensorboard
    - opencv-python
    - tqdm
    - scikit-image

   Create a conda environment by:
   ```
   conda create -n openstereo python=3.10 
   ```
   Install pytorch by [Anaconda](https://pytorch.org/get-started/locally/):
   ```
   conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia
   ```
   Install other dependencies by pip:
   ```
   pip install -r requirements.txt
   ```

## Prepare dataset

See [prepare dataset](2.prepare_dataset.md).

## Get trained model

Go to the [model zoom](1.model_zoo.md), then download the model file and uncompress it to output.

## Train

Train a model by

```
CUDA_VISIBLE_DEVICES=0,1 python openstereo/main.py --config ./configs/psmnet/PSMNet_sceneflow.yaml --scope train
```

- `--config` The path to config file.
- `--scope` Specified as `train`, `val` or `test_kitti`.
- `--restore_hint` You can specify a number of iterations or use `restore_hint` in the config file and resume training
  from there.
- `--master_addr` The master address of DDP.
- `--master_port` The master port of DDP.
- `--no_distribute` If specified, the program will not use DDP to train.
- `--device` The device to use, e.g. `cuda:0`. only used when `no_distribute` is specified.

## Val

Evaluate the trained model by

```
CUDA_VISIBLE_DEVICES=0,1 python openstereo/main.py --config ./configs/psmnet/PSMNet_sceneflow.yaml --scope val
```

- `--phase` Specified as `test`.
- `--restore_hint` Specify a checkpoint.

**Tip**: Other arguments are the same as train phase.

## Customize

1. Read the [detailed config](3.detailed_config.md) to figure out the usage of needed setting items;
2. See [how to create your model](4.how_to_create_your_model.md);
3. There are some advanced usages, refer to [advanced usages](5.advanced_usages.md), please.

## Other
1. You can set the default pretrained model path, by `export TORCH_HOME="/path/to/pretrained_models"`
